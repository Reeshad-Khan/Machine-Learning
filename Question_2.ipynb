{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Question 2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1kngz4XcIud1EZLtzNaTQBEQ67SEKMh1z",
      "authorship_tag": "ABX9TyO83g9yKTJAoc57eF2FW2VD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Reeshad-Khan/Machine-Learning/blob/master/Question_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GT9KjpeBDyLI"
      },
      "source": [
        "\n",
        "# **load required libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmpZ7haP_qcU"
      },
      "source": [
        "import pandas as pd\n",
        "import pylab as pl\n",
        "import numpy as np\n",
        "import scipy.optimize as opt\n",
        "from sklearn import preprocessing\n",
        "%matplotlib inline \n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "geXZDNxJDxZE"
      },
      "source": [
        "\n",
        "**Downloading data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-cTknNOD9oL",
        "outputId": "54700b3c-2fd8-40d8-82a4-ef9d2b9530e8"
      },
      "source": [
        "!wget -O data.csv https://drive.google.com/file/d/1NqjIYWiHAOKn5G_mCzgVBtaLpNVZ_SOO/view?usp=sharing"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-09 15:29:39--  https://drive.google.com/file/d/1NqjIYWiHAOKn5G_mCzgVBtaLpNVZ_SOO/view?usp=sharing\n",
            "Resolving drive.google.com (drive.google.com)... 209.85.200.139, 209.85.200.100, 209.85.200.113, ...\n",
            "Connecting to drive.google.com (drive.google.com)|209.85.200.139|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://accounts.google.com/ServiceLogin?service=wise&passive=1209600&continue=https://drive.google.com/file/d/1NqjIYWiHAOKn5G_mCzgVBtaLpNVZ_SOO/view?usp%3Dsharing&followup=https://drive.google.com/file/d/1NqjIYWiHAOKn5G_mCzgVBtaLpNVZ_SOO/view?usp%3Dsharing [following]\n",
            "--2021-04-09 15:29:39--  https://accounts.google.com/ServiceLogin?service=wise&passive=1209600&continue=https://drive.google.com/file/d/1NqjIYWiHAOKn5G_mCzgVBtaLpNVZ_SOO/view?usp%3Dsharing&followup=https://drive.google.com/file/d/1NqjIYWiHAOKn5G_mCzgVBtaLpNVZ_SOO/view?usp%3Dsharing\n",
            "Resolving accounts.google.com (accounts.google.com)... 108.177.121.84, 2607:f8b0:4001:c34::54\n",
            "Connecting to accounts.google.com (accounts.google.com)|108.177.121.84|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘data.csv’\n",
            "\n",
            "data.csv                [ <=>                ]  65.02K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2021-04-09 15:29:39 (90.1 MB/s) - ‘data.csv’ saved [66578]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHBK-UVZEea6"
      },
      "source": [
        "**Read data using pandas dataframe**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "Gd-ORZ98Ef0w",
        "outputId": "1ea577c9-98b3-43c4-8b2d-6472113f5734"
      },
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/data.csv', delimiter=\",\")\n",
        "df"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>3.7174</th>\n",
              "      <th>56.325</th>\n",
              "      <th>58.974</th>\n",
              "      <th>9.256</th>\n",
              "      <th>0.45627</th>\n",
              "      <th>5.795</th>\n",
              "      <th>13.638</th>\n",
              "      <th>-0.14328</th>\n",
              "      <th>1.7739</th>\n",
              "      <th>7.7725</th>\n",
              "      <th>20.93</th>\n",
              "      <th>19.234</th>\n",
              "      <th>3</th>\n",
              "      <th>1</th>\n",
              "      <th>4</th>\n",
              "      <th>1.1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.7534</td>\n",
              "      <td>56.749</td>\n",
              "      <td>56.848</td>\n",
              "      <td>9.5115</td>\n",
              "      <td>0.085101</td>\n",
              "      <td>10.3730</td>\n",
              "      <td>15.042</td>\n",
              "      <td>0.92653</td>\n",
              "      <td>0.35062</td>\n",
              "      <td>2.8064</td>\n",
              "      <td>18.145</td>\n",
              "      <td>18.972</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.0278</td>\n",
              "      <td>52.769</td>\n",
              "      <td>56.428</td>\n",
              "      <td>9.4282</td>\n",
              "      <td>0.781760</td>\n",
              "      <td>5.8555</td>\n",
              "      <td>17.612</td>\n",
              "      <td>0.08183</td>\n",
              "      <td>0.33566</td>\n",
              "      <td>3.2427</td>\n",
              "      <td>13.567</td>\n",
              "      <td>19.936</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.3783</td>\n",
              "      <td>44.768</td>\n",
              "      <td>57.687</td>\n",
              "      <td>9.7385</td>\n",
              "      <td>0.534460</td>\n",
              "      <td>6.0956</td>\n",
              "      <td>17.308</td>\n",
              "      <td>-1.53160</td>\n",
              "      <td>1.29820</td>\n",
              "      <td>8.7503</td>\n",
              "      <td>21.949</td>\n",
              "      <td>19.620</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.7983</td>\n",
              "      <td>46.136</td>\n",
              "      <td>59.557</td>\n",
              "      <td>9.8185</td>\n",
              "      <td>0.981570</td>\n",
              "      <td>9.5196</td>\n",
              "      <td>12.607</td>\n",
              "      <td>1.30570</td>\n",
              "      <td>1.16600</td>\n",
              "      <td>3.9632</td>\n",
              "      <td>17.934</td>\n",
              "      <td>19.480</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3.0917</td>\n",
              "      <td>51.560</td>\n",
              "      <td>57.406</td>\n",
              "      <td>9.1364</td>\n",
              "      <td>0.406030</td>\n",
              "      <td>9.2565</td>\n",
              "      <td>17.626</td>\n",
              "      <td>0.10152</td>\n",
              "      <td>0.34597</td>\n",
              "      <td>5.9328</td>\n",
              "      <td>22.293</td>\n",
              "      <td>19.664</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7994</th>\n",
              "      <td>2.9013</td>\n",
              "      <td>47.805</td>\n",
              "      <td>58.805</td>\n",
              "      <td>9.7700</td>\n",
              "      <td>0.196530</td>\n",
              "      <td>5.8620</td>\n",
              "      <td>12.993</td>\n",
              "      <td>1.45980</td>\n",
              "      <td>0.47724</td>\n",
              "      <td>6.9010</td>\n",
              "      <td>26.643</td>\n",
              "      <td>20.365</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7995</th>\n",
              "      <td>4.2219</td>\n",
              "      <td>40.969</td>\n",
              "      <td>57.781</td>\n",
              "      <td>9.2291</td>\n",
              "      <td>0.366670</td>\n",
              "      <td>8.4966</td>\n",
              "      <td>15.177</td>\n",
              "      <td>0.25724</td>\n",
              "      <td>1.03980</td>\n",
              "      <td>3.8663</td>\n",
              "      <td>22.070</td>\n",
              "      <td>19.177</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7996</th>\n",
              "      <td>2.2153</td>\n",
              "      <td>51.074</td>\n",
              "      <td>58.425</td>\n",
              "      <td>9.3208</td>\n",
              "      <td>0.195230</td>\n",
              "      <td>9.9987</td>\n",
              "      <td>16.745</td>\n",
              "      <td>0.11213</td>\n",
              "      <td>0.78606</td>\n",
              "      <td>4.8264</td>\n",
              "      <td>21.871</td>\n",
              "      <td>20.084</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7997</th>\n",
              "      <td>6.4175</td>\n",
              "      <td>25.005</td>\n",
              "      <td>52.064</td>\n",
              "      <td>11.1930</td>\n",
              "      <td>1.584400</td>\n",
              "      <td>10.3250</td>\n",
              "      <td>18.212</td>\n",
              "      <td>0.88258</td>\n",
              "      <td>4.84840</td>\n",
              "      <td>10.4460</td>\n",
              "      <td>21.665</td>\n",
              "      <td>16.052</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7998</th>\n",
              "      <td>3.3657</td>\n",
              "      <td>40.319</td>\n",
              "      <td>55.561</td>\n",
              "      <td>9.7822</td>\n",
              "      <td>0.739210</td>\n",
              "      <td>7.4166</td>\n",
              "      <td>12.935</td>\n",
              "      <td>2.04760</td>\n",
              "      <td>1.00420</td>\n",
              "      <td>4.3027</td>\n",
              "      <td>23.582</td>\n",
              "      <td>19.791</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7999 rows × 16 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      3.7174  56.325  58.974    9.256   0.45627  ...  19.234  3  1   4  1.1\n",
              "0     2.7534  56.749  56.848   9.5115  0.085101  ...  18.972  1  2   3    1\n",
              "1     2.0278  52.769  56.428   9.4282  0.781760  ...  19.936  2  1   1    1\n",
              "2     3.3783  44.768  57.687   9.7385  0.534460  ...  19.620  1  1   4    1\n",
              "3     3.7983  46.136  59.557   9.8185  0.981570  ...  19.480  1  2   3    1\n",
              "4     3.0917  51.560  57.406   9.1364  0.406030  ...  19.664  4  1   5    1\n",
              "...      ...     ...     ...      ...       ...  ...     ... .. ..  ..  ...\n",
              "7994  2.9013  47.805  58.805   9.7700  0.196530  ...  20.365  1  2   3    1\n",
              "7995  4.2219  40.969  57.781   9.2291  0.366670  ...  19.177  3  1   5    1\n",
              "7996  2.2153  51.074  58.425   9.3208  0.195230  ...  20.084  2  1   3    1\n",
              "7997  6.4175  25.005  52.064  11.1930  1.584400  ...  16.052  5  3  10    2\n",
              "7998  3.3657  40.319  55.561   9.7822  0.739210  ...  19.791  2  2   1    1\n",
              "\n",
              "[7999 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4rOpmDDdGCPK",
        "outputId": "f0cea233-886d-4d17-f87d-98dcb8138d4d"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7999, 16)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "nIRiMy5ZGggs",
        "outputId": "7952830d-5e31-440b-83d9-bb47ccb74977"
      },
      "source": [
        "sample = df.iloc[:,0:15]\n",
        "sample"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>3.7174</th>\n",
              "      <th>56.325</th>\n",
              "      <th>58.974</th>\n",
              "      <th>9.256</th>\n",
              "      <th>0.45627</th>\n",
              "      <th>5.795</th>\n",
              "      <th>13.638</th>\n",
              "      <th>-0.14328</th>\n",
              "      <th>1.7739</th>\n",
              "      <th>7.7725</th>\n",
              "      <th>20.93</th>\n",
              "      <th>19.234</th>\n",
              "      <th>3</th>\n",
              "      <th>1</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.7534</td>\n",
              "      <td>56.749</td>\n",
              "      <td>56.848</td>\n",
              "      <td>9.5115</td>\n",
              "      <td>0.085101</td>\n",
              "      <td>10.3730</td>\n",
              "      <td>15.042</td>\n",
              "      <td>0.92653</td>\n",
              "      <td>0.35062</td>\n",
              "      <td>2.8064</td>\n",
              "      <td>18.145</td>\n",
              "      <td>18.972</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.0278</td>\n",
              "      <td>52.769</td>\n",
              "      <td>56.428</td>\n",
              "      <td>9.4282</td>\n",
              "      <td>0.781760</td>\n",
              "      <td>5.8555</td>\n",
              "      <td>17.612</td>\n",
              "      <td>0.08183</td>\n",
              "      <td>0.33566</td>\n",
              "      <td>3.2427</td>\n",
              "      <td>13.567</td>\n",
              "      <td>19.936</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.3783</td>\n",
              "      <td>44.768</td>\n",
              "      <td>57.687</td>\n",
              "      <td>9.7385</td>\n",
              "      <td>0.534460</td>\n",
              "      <td>6.0956</td>\n",
              "      <td>17.308</td>\n",
              "      <td>-1.53160</td>\n",
              "      <td>1.29820</td>\n",
              "      <td>8.7503</td>\n",
              "      <td>21.949</td>\n",
              "      <td>19.620</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.7983</td>\n",
              "      <td>46.136</td>\n",
              "      <td>59.557</td>\n",
              "      <td>9.8185</td>\n",
              "      <td>0.981570</td>\n",
              "      <td>9.5196</td>\n",
              "      <td>12.607</td>\n",
              "      <td>1.30570</td>\n",
              "      <td>1.16600</td>\n",
              "      <td>3.9632</td>\n",
              "      <td>17.934</td>\n",
              "      <td>19.480</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3.0917</td>\n",
              "      <td>51.560</td>\n",
              "      <td>57.406</td>\n",
              "      <td>9.1364</td>\n",
              "      <td>0.406030</td>\n",
              "      <td>9.2565</td>\n",
              "      <td>17.626</td>\n",
              "      <td>0.10152</td>\n",
              "      <td>0.34597</td>\n",
              "      <td>5.9328</td>\n",
              "      <td>22.293</td>\n",
              "      <td>19.664</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7994</th>\n",
              "      <td>2.9013</td>\n",
              "      <td>47.805</td>\n",
              "      <td>58.805</td>\n",
              "      <td>9.7700</td>\n",
              "      <td>0.196530</td>\n",
              "      <td>5.8620</td>\n",
              "      <td>12.993</td>\n",
              "      <td>1.45980</td>\n",
              "      <td>0.47724</td>\n",
              "      <td>6.9010</td>\n",
              "      <td>26.643</td>\n",
              "      <td>20.365</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7995</th>\n",
              "      <td>4.2219</td>\n",
              "      <td>40.969</td>\n",
              "      <td>57.781</td>\n",
              "      <td>9.2291</td>\n",
              "      <td>0.366670</td>\n",
              "      <td>8.4966</td>\n",
              "      <td>15.177</td>\n",
              "      <td>0.25724</td>\n",
              "      <td>1.03980</td>\n",
              "      <td>3.8663</td>\n",
              "      <td>22.070</td>\n",
              "      <td>19.177</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7996</th>\n",
              "      <td>2.2153</td>\n",
              "      <td>51.074</td>\n",
              "      <td>58.425</td>\n",
              "      <td>9.3208</td>\n",
              "      <td>0.195230</td>\n",
              "      <td>9.9987</td>\n",
              "      <td>16.745</td>\n",
              "      <td>0.11213</td>\n",
              "      <td>0.78606</td>\n",
              "      <td>4.8264</td>\n",
              "      <td>21.871</td>\n",
              "      <td>20.084</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7997</th>\n",
              "      <td>6.4175</td>\n",
              "      <td>25.005</td>\n",
              "      <td>52.064</td>\n",
              "      <td>11.1930</td>\n",
              "      <td>1.584400</td>\n",
              "      <td>10.3250</td>\n",
              "      <td>18.212</td>\n",
              "      <td>0.88258</td>\n",
              "      <td>4.84840</td>\n",
              "      <td>10.4460</td>\n",
              "      <td>21.665</td>\n",
              "      <td>16.052</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7998</th>\n",
              "      <td>3.3657</td>\n",
              "      <td>40.319</td>\n",
              "      <td>55.561</td>\n",
              "      <td>9.7822</td>\n",
              "      <td>0.739210</td>\n",
              "      <td>7.4166</td>\n",
              "      <td>12.935</td>\n",
              "      <td>2.04760</td>\n",
              "      <td>1.00420</td>\n",
              "      <td>4.3027</td>\n",
              "      <td>23.582</td>\n",
              "      <td>19.791</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7999 rows × 15 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      3.7174  56.325  58.974    9.256   0.45627  ...   20.93  19.234  3  1   4\n",
              "0     2.7534  56.749  56.848   9.5115  0.085101  ...  18.145  18.972  1  2   3\n",
              "1     2.0278  52.769  56.428   9.4282  0.781760  ...  13.567  19.936  2  1   1\n",
              "2     3.3783  44.768  57.687   9.7385  0.534460  ...  21.949  19.620  1  1   4\n",
              "3     3.7983  46.136  59.557   9.8185  0.981570  ...  17.934  19.480  1  2   3\n",
              "4     3.0917  51.560  57.406   9.1364  0.406030  ...  22.293  19.664  4  1   5\n",
              "...      ...     ...     ...      ...       ...  ...     ...     ... .. ..  ..\n",
              "7994  2.9013  47.805  58.805   9.7700  0.196530  ...  26.643  20.365  1  2   3\n",
              "7995  4.2219  40.969  57.781   9.2291  0.366670  ...  22.070  19.177  3  1   5\n",
              "7996  2.2153  51.074  58.425   9.3208  0.195230  ...  21.871  20.084  2  1   3\n",
              "7997  6.4175  25.005  52.064  11.1930  1.584400  ...  21.665  16.052  5  3  10\n",
              "7998  3.3657  40.319  55.561   9.7822  0.739210  ...  23.582  19.791  2  2   1\n",
              "\n",
              "[7999 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "zk4C_GRfHLdi",
        "outputId": "fd8615a7-42b3-48d7-ed24-81b857a2f713"
      },
      "source": [
        "label = df.iloc[:,-1:]\n",
        "label"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1.1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7994</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7995</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7996</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7997</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7998</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7999 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      1.1\n",
              "0       1\n",
              "1       1\n",
              "2       1\n",
              "3       1\n",
              "4       1\n",
              "...   ...\n",
              "7994    1\n",
              "7995    1\n",
              "7996    1\n",
              "7997    2\n",
              "7998    1\n",
              "\n",
              "[7999 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJRvNPw5J4jh"
      },
      "source": [
        "**Lets define X, and y for our dataset:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Vol2eNGJ5i8",
        "outputId": "86ac1695-a29e-4471-b205-2feaf6ad60cb"
      },
      "source": [
        "X = np.asarray(sample)\n",
        "X"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 2.75, 56.75, 56.85, ...,  1.  ,  2.  ,  3.  ],\n",
              "       [ 2.03, 52.77, 56.43, ...,  2.  ,  1.  ,  1.  ],\n",
              "       [ 3.38, 44.77, 57.69, ...,  1.  ,  1.  ,  4.  ],\n",
              "       ...,\n",
              "       [ 2.22, 51.07, 58.42, ...,  2.  ,  1.  ,  3.  ],\n",
              "       [ 6.42, 25.  , 52.06, ...,  5.  ,  3.  , 10.  ],\n",
              "       [ 3.37, 40.32, 55.56, ...,  2.  ,  2.  ,  1.  ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSykblvAKFsM",
        "outputId": "39a72766-4c61-43fd-9c56-ff49a68fae7d"
      },
      "source": [
        "y = np.asarray(label)\n",
        "y"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1],\n",
              "       [1],\n",
              "       [1],\n",
              "       ...,\n",
              "       [1],\n",
              "       [2],\n",
              "       [1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKPsgNKfKPoi"
      },
      "source": [
        "**Also, we normalize the dataset:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xo0t2NXbKQ06",
        "outputId": "e3270b8d-2abd-4ee3-8ae7-617724b137ad"
      },
      "source": [
        "from sklearn import preprocessing\n",
        "X = preprocessing.StandardScaler().fit(X).transform(X)\n",
        "X"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.85,  1.14,  0.2 , ..., -1.17,  0.14, -0.38],\n",
              "       [-1.33,  0.67,  0.1 , ..., -0.64, -0.95, -1.21],\n",
              "       [-0.43, -0.27,  0.4 , ..., -1.17, -0.95,  0.04],\n",
              "       ...,\n",
              "       [-1.21,  0.47,  0.58, ..., -0.64, -0.95, -0.38],\n",
              "       [ 1.59, -2.59, -0.95, ...,  0.95,  1.23,  2.55],\n",
              "       [-0.44, -0.79, -0.11, ..., -0.64,  0.14, -1.21]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XWSiq4EkKVYp"
      },
      "source": [
        "# Train/Test dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svp9RhK7KZSb"
      },
      "source": [
        "**Okay, we split our dataset into train and test set:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6qKhwjwFKXmS",
        "outputId": "79b78442-b644-44e1-e9e2-d79a59f7a79d"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=4)\n",
        "print ('Train set:', X_train.shape,  y_train.shape)\n",
        "print ('Test set:', X_test.shape,  y_test.shape)"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train set: (6399, 15) (6399, 1)\n",
            "Test set: (1600, 15) (1600, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnzqAmM3KkSF"
      },
      "source": [
        "## Modeling (Logistic Regression with Scikit-learn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHsDcqI-PU9w"
      },
      "source": [
        "We build our model using **LogisticRegression** from Scikit-learn package. This function implements logistic regression and can use different numerical optimizers to find parameters, including ‘newton-cg’, ‘lbfgs’, ‘liblinear’, ‘sag’, ‘saga’ solvers.\n",
        "\n",
        "The version of Logistic Regression in Scikit-learn, support regularization. Regularization is a technique used to solve the overfitting problem in machine learning models. **C** parameter indicates **inverse of regularization strength** which must be a positive float. Smaller values specify stronger regularization. We fit our model with train set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rPA0VaZoKmAz",
        "outputId": "31abc4b1-04be-46cb-a933-21cf564105b7"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix\n",
        "LR = LogisticRegression(C=0.01, solver='liblinear').fit(X_train,y_train)\n",
        "LR"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_x6yGcoKqBs"
      },
      "source": [
        "**Now we can predict using our test set:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S8fvZYsYKq5z",
        "outputId": "f6ab554e-de72-4cdb-ceb3-a490914a97e9"
      },
      "source": [
        "yhat = LR.predict(X_test)\n",
        "yhat"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 1, 1, ..., 2, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZdxUhDf8KvaC"
      },
      "source": [
        "**predict_proba** returns estimates for all classes, ordered by the label of classes. So, the first column is the probability of class 0, P(Y=0|X), and second column is probability of class 1, P(Y=1|X):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3vqVio4TKyJ7",
        "outputId": "27284b35-cedb-42b8-8544-12d2d5a34509"
      },
      "source": [
        "yhat_prob = LR.predict_proba(X_test)\n",
        "yhat_prob"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5.00e-04, 9.99e-01],\n",
              "       [9.85e-01, 1.45e-02],\n",
              "       [9.58e-01, 4.21e-02],\n",
              "       ...,\n",
              "       [1.15e-03, 9.99e-01],\n",
              "       [9.84e-01, 1.63e-02],\n",
              "       [9.96e-01, 3.83e-03]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ABjdchkK19F"
      },
      "source": [
        "## **Evaluation**\n",
        "\n",
        "**jaccard index¶**\n",
        "\n",
        "Lets try jaccard index for accuracy evaluation. we can define jaccard as the size of the intersection divided by the size of the union of two label sets. If the entire set of predicted labels for a sample strictly match with the true set of labels, then the subset accuracy is 1.0; otherwise it is 0.0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWqpjf4WK__F",
        "outputId": "70c701d9-a685-491b-9458-6b0eb76c77b1"
      },
      "source": [
        "from sklearn.metrics import jaccard_score\n",
        "jaccard_score(y_test, yhat)"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMZjn8ssLgeX"
      },
      "source": [
        "## **confusion matrix¶**\n",
        "Another way of looking at accuracy of classifier is to look at **confusion matrix**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZbTHDHjILmEv",
        "outputId": "19c0107a-bf85-440a-ae91-e1c040314d6d"
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import itertools\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "print(confusion_matrix(y_test, yhat, labels=[1,0]))"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1299    0]\n",
            " [   0    0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "CrEIbTTnLvWT",
        "outputId": "026729bc-adef-4ead-b614-e5e300512fd8"
      },
      "source": [
        "# Compute confusion matrix\n",
        "cnf_matrix = confusion_matrix(y_test, yhat, labels=[1,0])\n",
        "np.set_printoptions(precision=2)\n",
        "\n",
        "\n",
        "# Plot non-normalized confusion matrix\n",
        "plt.figure()\n",
        "plot_confusion_matrix(cnf_matrix, classes=['churn=1','churn=0'],normalize= False,  title='Confusion matrix')"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix, without normalization\n",
            "[[1299    0]\n",
            " [   0    0]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2zyuXWVrL2fl",
        "outputId": "3b2d137a-1308-450f-b60b-0f20c5558920"
      },
      "source": [
        "print (classification_report(y_test, yhat))"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00      1299\n",
            "           2       1.00      1.00      1.00       301\n",
            "\n",
            "    accuracy                           1.00      1600\n",
            "   macro avg       1.00      1.00      1.00      1600\n",
            "weighted avg       1.00      1.00      1.00      1600\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1R4Tb_fSTBO"
      },
      "source": [
        "**log loss**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ms3wXLDXL7BF",
        "outputId": "1c23395b-3009-477c-a339-5178d1d8e86c"
      },
      "source": [
        "from sklearn.metrics import log_loss\n",
        "log_loss(y_test, yhat_prob)"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.025625369101540656"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SyU4HE8ELk8l"
      },
      "source": [
        ""
      ]
    }
  ]
}