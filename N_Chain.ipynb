{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "N-Chain.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOcrweEVV6bnuN04EknMAb4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Reeshad-Khan/Machine-Learning/blob/master/N_Chain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ns_BfKYofbd7"
      },
      "source": [
        "# **5-state Chain problem using the NChain-v0 Environment in Open AI Gym**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dMasPn7nuJMq",
        "outputId": "5ccf0c96-32ba-46f5-9011-a85aebb52199"
      },
      "source": [
        "import gym \r\n",
        "import numpy as np\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import InputLayer, Dense\r\n",
        "from tqdm import trange\r\n",
        "\r\n",
        "\r\n",
        "model = Sequential()\r\n",
        "model.add(InputLayer(batch_input_shape=(1, 5)))\r\n",
        "model.add(Dense(10, activation='sigmoid'))\r\n",
        "model.add(Dense(2, activation='linear'))\r\n",
        "model.compile(loss='mse', optimizer='adam', metrics=['mae'])\r\n",
        "\r\n",
        "\r\n",
        "def eps_q_learn_nn_train(env, num_episodes=500):\r\n",
        "    # now execute the q learning\r\n",
        "    y = 0.95\r\n",
        "    eps = 0.5\r\n",
        "    decay_factor = 0.999\r\n",
        "    r_avg_list = []\r\n",
        "    for _ in trange(num_episodes):\r\n",
        "        s = env.reset()\r\n",
        "        eps *= decay_factor\r\n",
        "        done = False\r\n",
        "        r_sum = 0\r\n",
        "        while not done:\r\n",
        "            if np.random.random() < eps:\r\n",
        "                a = np.random.randint(0, 2)\r\n",
        "            else:\r\n",
        "                a = np.argmax(model.predict(np.identity(5)[s:s + 1]))\r\n",
        "            new_s, r, done, _ = env.step(a)\r\n",
        "            target = r + y * np.max(model.predict(np.identity(5)[new_s:new_s + 1]))\r\n",
        "            target_vec = model.predict(np.identity(5)[s:s + 1])[0]\r\n",
        "            target_vec[a] = target\r\n",
        "            model.fit(np.identity(5)[s:s + 1], target_vec.reshape(-1, 2), epochs=1, verbose=0)\r\n",
        "            s = new_s\r\n",
        "            r_sum += r\r\n",
        "        r_avg_list.append(r_sum / 1000)\r\n",
        "\r\n",
        "def display_q_table():\r\n",
        "    for s in range(5):\r\n",
        "        print(model.predict(np.identity(5)[s:s + 1])[0])\r\n",
        "\r\n",
        "if __name__=='__main__':\r\n",
        "    env = gym.make('NChain-v0')\r\n",
        "    env.reset()\r\n",
        "    eps_q_learn_nn_train(env)\r\n",
        "    print(\"Training complete\")\r\n",
        "    display_q_table()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [02:27<00:00, 147.55s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training complete\n",
            "[3.3418117 6.1568093]\n",
            "[3.193335 6.165882]\n",
            "[3.0729675 5.799858 ]\n",
            "[3.1306124 5.848181 ]\n",
            "[3.1314082 6.028343 ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygqIzK6f7wnQ"
      },
      "source": [
        "References I have used:\r\n",
        "\r\n",
        "1. http://adventuresinmachinelearning.com/reinforcement-learning-tutorial-python-keras/\r\n",
        "2. https://youtube.com/playlist?list=PLQVvvaa0QuDezJFIOU5wDdfy4e9vdnx-7\r\n",
        "3. https://classroom.udacity.com/courses/ud600"
      ]
    }
  ]
}